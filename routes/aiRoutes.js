const express = require('express');
const router = express.Router();
const openai = require('../config/openai');

// ğŸ”® ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ OpenAI ì‘ë‹µ ìƒì„±
router.post('/generate-response', async (req, res) => {
  const { questions, userMessage } = req.body;

  // ì§ˆë¬¸ê³¼ ë‹µë³€ì„ OpenAI ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
  const baseMessages = questions.map((q) => ({
    role: 'user',
    content: `Q: ${q.questionText}\nA: ${q.answerText}`,
  }));

  baseMessages.push({ role: 'user', content: userMessage });

  try {
    // OpenAI API í˜¸ì¶œ
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: 'You are a helpful assistant who speaks like a philosopher.' },
        ...baseMessages,
      ],
      max_tokens: 150,
      temperature: 0.7,
    });

    const aiResponse = response.choices[0].message.content.trim();

    res.json({
      message: 'AI response generated successfully!',
      aiResponse,
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// ğŸ”® ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ê° stageë³„ ìš”ì•½ ìƒì„±
router.post('/generate-statistics', async (req, res) => {
  const { questions } = req.body;

  // ê° stageë³„ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê·¸ë£¹í™”
  const groupedByStage = questions.reduce((acc, question) => {
    const { stage, questionText, answerText } = question;
    if (!acc[stage]) {
      acc[stage] = [];
    }
    acc[stage].push(`Q: ${questionText}\nA: ${answerText}`);
    return acc;
  }, {});

  // OpenAI API ìš”ì²­ ë©”ì‹œì§€ ìƒì„±
  const stageSummaries = [];
  for (const [stage, messages] of Object.entries(groupedByStage)) {
    const messageContent = messages.join('\n\n');
    const systemMessage = `Summarize the following answers into 2-3 lines for stage ${stage}. Use a warm and empathetic tone. ë‹¹ì‹ ì€ ~í•œ ì‚¬ëŒì´ë„¤ìš”! ê°™ì€ ì–´ê°ìœ¼ë¡œ ë‚˜ì— ëŒ€í•´ ìƒˆë¡­ê²Œ ì•Œê²Œëœ ì ì„ ë‚˜ì—´í•˜ëŠ” ë§íˆ¬ë¡œ í•´ì¤˜.`;

    try {
      // OpenAI API í˜¸ì¶œ
      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: systemMessage },
          { role: 'user', content: messageContent },
        ],
        max_tokens: 200,
        temperature: 0.7,
      });

      // AI ì‘ë‹µ ì €ì¥
      const aiSummary = response.choices[0].message.content.trim();
      stageSummaries.push({
        stage: parseInt(stage),
        summary: aiSummary,
      });
    } catch (error) {
      return res.status(500).json({ error: `OpenAI API error for stage ${stage}: ${error.message}` });
    }
  }

  // ëª¨ë“  stage ìš”ì•½ ë°˜í™˜
  res.json({
    message: 'Stage summaries generated successfully!',
    summaries: stageSummaries,
  });
});

module.exports = router;
