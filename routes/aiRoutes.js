const express = require('express');
const router = express.Router();
const openai = require('../config/openai');

// ğŸ”® ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤ ëŒ€í™” ìƒì„± API
router.post('/generate-response/aristotle', async (req, res) => {
  const { questions = [], userMessage } = req.body; // questions ê¸°ë³¸ê°’ì„ ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •

  if (!userMessage) {
    return res.status(400).json({ error: 'userMessageëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.' });
  }

  try {
    const baseMessages = questions.map((q) => ({
      role: 'user',
      content: `Q: ${q.questionText}\nA: ${q.answerText}`,
    }));

    baseMessages.push({ role: 'user', content: userMessage });

    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: 'ë‹¹ì‹ ì€ ê³ ëŒ€ ì² í•™ì ì•„ë¦¬ìŠ¤í†  í…”ë ˆìŠ¤ì…ë‹ˆë‹¤. ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤ëŠ” í˜„ì‹¤ ì„¸ê³„ì˜ ê²½í—˜ê³¼ ê´€ì°°ì„ ì¤‘ì‹œí•˜ë©°, ë§Œë¬¼ì˜ ëª©ì ê³¼ ë³¸ì§ˆì„ íƒêµ¬í•˜ëŠ” ëª©ì ë¡ ì  ì„¸ê³„ê´€ì„ ì œì‹œí–ˆë‹¤. ê·¸ëŠ” ìœ¤ë¦¬ì ìœ¼ë¡œëŠ” ë•ì„ í†µí•œ ì¤‘ìš©ì˜ ì‚¶ì„, ì •ì¹˜ì ìœ¼ë¡œëŠ” ê³µë™ì²´ì˜ í–‰ë³µì„ ìµœìš°ì„ ìœ¼ë¡œ ì—¬ê²¼ë‹¤.ì‚¬ëŒë“¤ì˜ ìƒë‹´ì„ í•´ì£¼ì§€ìš”. ê·¸ ìƒë‹´ë°›ëŠ” ì‚¬ëŒì˜ ì‚¬ì „ ì •ë³´ë¥¼ ì•„ë¦¬ìŠ¤í†  í…”ë ˆìŠ¤ëŠ” ì•Œê³ ìˆìŠµë‹ˆë‹¤. ê·¸ê±¸ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ëŒì–´ê°€ì„¸ìš”. ë©‹ì§„ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”. ë‹µì€ ê°„ê²°í•˜ê²Œ 2ì¤„ê¹Œì§€.' },
        ...baseMessages,
      ],
      max_tokens: 150,
      temperature: 0.7,
    });

    const aiResponse = response.choices[0].message.content.trim();

    res.json({ message: 'Aristotle response generated successfully!', aiResponse });
  } catch (error) {
    console.error('AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
    res.status(500).json({ error: error.message });
  }
});


// ğŸ”® ì‡¼íœí•˜ìš°ì–´ ëŒ€í™” ìƒì„± API
router.post('/generate-response/schopenhauer', async (req, res) => {
  const { questions = [], userMessage } = req.body; // questions ê¸°ë³¸ê°’ì„ ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •

  if (!userMessage) {
    return res.status(400).json({ error: 'userMessageëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.' });
  }

  try {
    const baseMessages = questions.map((q) => ({
      role: 'user',
      content: `Q: ${q.questionText}\nA: ${q.answerText}`,
    }));

    baseMessages.push({ role: 'user', content: userMessage });

    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: 'ë‹¹ì‹ ì€ ë¹„ê´€ì£¼ì˜ ì² í•™ì ì‡¼íœí•˜ìš°ì–´ì…ë‹ˆë‹¤. ì‡¼íœí•˜ìš°ì–´ëŠ” ì‚¶ì˜ ê³ í†µê³¼ ë¬´ì˜ë¯¸í•¨ì„ ì¸ì‹í•˜ë©°, ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì˜ì§€ì˜ ë¶€ì •ì„ í†µí•œ í‰ì˜¨ê³¼ ì˜ˆìˆ ì˜ ê°€ì¹˜ë¥¼ ê°•ì¡°í–ˆë‹¤. ì‚¬ëŒë“¤ì˜ ìƒë‹´ì„ í•´ì£¼ì§€ìš”. ê·¸ ìƒë‹´ë°›ëŠ” ì‚¬ëŒì˜ ì‚¬ì „ ì •ë³´ë¥¼ ì‡¼íœí•˜ìš°ì–´ëŠ” ì•Œê³ ìˆìŠµë‹ˆë‹¤. ê·¸ê±¸ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ëŒì–´ê°€ì„¸ìš”. ë©‹ì§„ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”. ë‹µì€ ê°„ê²°í•˜ê²Œ 2ì¤„ê¹Œì§€.' },
        ...baseMessages,
      ],
      max_tokens: 150,
      temperature: 0.7,
    });

    const aiResponse = response.choices[0].message.content.trim();

    res.json({ message: 'Aristotle response generated successfully!', aiResponse });
  } catch (error) {
    console.error('AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
    res.status(500).json({ error: error.message });
  }
});


// ğŸ”® ì†Œí¬ë¼í…ŒìŠ¤ìŠ¤ ëŒ€í™” ìƒì„± API
router.post('/generate-response/socrates', async (req, res) => {
  const { questions = [], userMessage } = req.body; // questions ê¸°ë³¸ê°’ì„ ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •

  if (!userMessage) {
    return res.status(400).json({ error: 'userMessageëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.' });
  }

  try {
    const baseMessages = questions.map((q) => ({
      role: 'user',
      content: `Q: ${q.questionText}\nA: ${q.answerText}`,
    }));

    baseMessages.push({ role: 'user', content: userMessage });

    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: 'ë‹¹ì‹ ì€ ê³ ëŒ€ ì² í•™ì ì†Œí¬ë¼í…ŒìŠ¤ì…ë‹ˆë‹¤. ì†Œí¬ë¼í…ŒìŠ¤ëŠ” ë¬´ì§€ë¥¼ ì¸ì •í•˜ê³  ì§ˆë¬¸ê³¼ ëŒ€í™”ë¥¼ í†µí•´ ì§„ë¦¬ë¥¼ íƒêµ¬í•˜ëŠ” ë°©ë²•ì„ ê°•ì¡°í•˜ë©°, â€œë„ˆ ìì‹ ì„ ì•Œë¼â€ë¼ëŠ” ê²©ì–¸ìœ¼ë¡œ ìœ ëª…í•˜ë‹¤. ì‚¬ëŒë“¤ì˜ ìƒë‹´ì„ í•´ì£¼ì§€ìš”. ê·¸ ìƒë‹´ë°›ëŠ” ì‚¬ëŒì˜ ì‚¬ì „ ì •ë³´ë¥¼ ì†Œí¬ë¼í…ŒìŠ¤ëŠ” ì•Œê³ ìˆìŠµë‹ˆë‹¤. ê·¸ê±¸ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ëŒì–´ê°€ì„¸ìš”. ë©‹ì§„ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”. ë‹µì€ ê°„ê²°í•˜ê²Œ 2ì¤„ê¹Œì§€.' },
        ...baseMessages,
      ],
      max_tokens: 150,
      temperature: 0.7,
    });

    const aiResponse = response.choices[0].message.content.trim();

    res.json({ message: 'Aristotle response generated successfully!', aiResponse });
  } catch (error) {
    console.error('AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
    res.status(500).json({ error: error.message });
  }
});



// ğŸ”® ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ê° stageë³„ ìš”ì•½ ìƒì„±
router.post('/generate-statistics', async (req, res) => {
  const { questions } = req.body;

  // ê° stageë³„ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê·¸ë£¹í™”
  const groupedByStage = questions.reduce((acc, question) => {
    const { stage, questionText, answerText } = question;
    if (!acc[stage]) {
      acc[stage] = [];
    }
    acc[stage].push(`Q: ${questionText}\nA: ${answerText}`);
    return acc;
  }, {});

  // OpenAI API ìš”ì²­ ë©”ì‹œì§€ ìƒì„±
  const stageSummaries = [];
  for (const [stage, messages] of Object.entries(groupedByStage)) {
    const messageContent = messages.join('\n\n');
    const systemMessage = `Summarize the following answers into 2-3 lines for stage ${stage}. Use a warm and empathetic tone. ë‹¹ì‹ ì€ ~í•œ ì‚¬ëŒì´ë„¤ìš”! ê°™ì€ ì–´ê°ìœ¼ë¡œ ë‚˜ì— ëŒ€í•´ ìƒˆë¡­ê²Œ ì•Œê²Œëœ ì ì„ ë‚˜ì—´í•˜ëŠ” ë§íˆ¬ë¡œ í•´ì¤˜.`;

    try {
      // OpenAI API í˜¸ì¶œ
      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: systemMessage },
          { role: 'user', content: messageContent },
        ],
        max_tokens: 200,
        temperature: 0.7,
      });

      // AI ì‘ë‹µ ì €ì¥
      const aiSummary = response.choices[0].message.content.trim();
      stageSummaries.push({
        stage: parseInt(stage),
        summary: aiSummary,
      });
    } catch (error) {
      return res.status(500).json({ error: `OpenAI API error for stage ${stage}: ${error.message}` });
    }
  }

  // ëª¨ë“  stage ìš”ì•½ ë°˜í™˜
  res.json({
    message: 'Stage summaries generated successfully!',
    summaries: stageSummaries,
  });
});

module.exports = router;
